{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ”¹ Objective (Report Text You Can Use)\n",
        "\n",
        "The objective of this task is to study and implement multiple transformer-based methods to identify differences between two\n",
        "texts. Instead of using OpenAI APIs, Hugging Face transformer models are used to compute semantic similarity, lexical\n",
        "difference, factual difference, and logical contradiction. The system is evaluated on sentences and documents such as resumes."
      ],
      "metadata": {
        "id": "tq2Ombob0-Ut"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "ljYx93jg0g2S",
        "outputId": "49f94aa5-285c-4b71-c4af-687d2031b322"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.8-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Collecting torch\n",
            "  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Collecting pdfminer.six==20251107 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20251107-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-5.2.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: joblib>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
            "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
            "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.5.1 (from torch)\n",
            "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.23)\n",
            "Downloading pdfplumber-0.11.8-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20251107-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-5.2.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, pypdfium2, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, scikit-learn, pdfminer.six, nvidia-cusolver-cu12, torch, pdfplumber\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.28.9\n",
            "    Uninstalling nvidia-nccl-cu12-2.28.9:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.28.9\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.0+cpu\n",
            "    Uninstalling torch-2.9.0+cpu:\n",
            "      Successfully uninstalled torch-2.9.0+cpu\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.9.0+cpu requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "torchvision 0.24.0+cpu requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.4.0 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.4.0 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.4.0 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 pdfminer.six-20251107 pdfplumber-0.11.8 pypdfium2-5.2.0 scikit-learn-1.8.0 torch-2.9.1 triton-3.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "7d238699ea584dc4b93593292eb78037"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -U sentence-transformers transformers pdfplumber scikit-learn torch numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pdfplumber\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "uGUw7IJE3YNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3ï¸âƒ£ Load Transformer Models\n",
        "\n",
        "Explanation (Report Text)\n",
        "\n",
        "Sentence-BERT is used to generate sentence embeddings for semantic comparison.\n",
        "BART-MNLI is used for Natural Language Inference to detect contradictions."
      ],
      "metadata": {
        "id": "-NMW7t6A3oju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Semantic embedding model\n",
        "semantic_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# NLI model for contradiction detection\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-mnli\")\n",
        "nli_model = AutoModelForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\")\n",
        "nli_model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "D7n04xPf3bbm",
        "outputId": "bf224cb3-9d71-4b81-fe8c-980209c334be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BartForSequenceClassification(\n",
              "  (model): BartModel(\n",
              "    (shared): BartScaledWordEmbedding(50265, 1024, padding_idx=1)\n",
              "    (encoder): BartEncoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(50265, 1024, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): BartDecoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(50265, 1024, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (classification_head): BartClassificationHead(\n",
              "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    (dropout): Dropout(p=0.0, inplace=False)\n",
              "    (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4ï¸âƒ£ Semantic Difference (Embedding-Based)\n",
        "Explanation\n",
        "\n",
        "Semantic difference is computed using cosine similarity between sentence embeddings. A threshold converts similarity scores into a binary decision."
      ],
      "metadata": {
        "id": "yniXCeyL4Awq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def semantic_difference(text_a, text_b, threshold=0.8):\n",
        "    emb_a = semantic_model.encode(text_a)\n",
        "    emb_b = semantic_model.encode(text_b)\n",
        "\n",
        "    similarity = cosine_similarity([emb_a], [emb_b])[0][0]\n",
        "\n",
        "    return {\n",
        "        \"similarity_score\": round(float(similarity), 4),\n",
        "        \"semantic_difference\": similarity < threshold\n",
        "    }\n"
      ],
      "metadata": {
        "id": "io-JNQpG3num"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5ï¸âƒ£ Lexical (Exact Text) Difference\n",
        "Explanation\n",
        "\n",
        "Lexical difference measures changes in wording without understanding meaning."
      ],
      "metadata": {
        "id": "VIJ8jbEN4KXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import difflib\n",
        "\n",
        "def lexical_difference(text_a, text_b):\n",
        "    ratio = difflib.SequenceMatcher(None, text_a, text_b).ratio()\n",
        "    return {\n",
        "        \"lexical_similarity\": round(ratio, 4),\n",
        "        \"lexical_difference\": ratio < 0.9\n",
        "    }\n"
      ],
      "metadata": {
        "id": "IRoRr_Bk4EUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6ï¸âƒ£ Factual Difference (Numbers & Quantities)\n",
        "Explanation\n",
        "\n",
        "Factual differences are detected by extracting numerical values from text."
      ],
      "metadata": {
        "id": "h-kXGB-i4UDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_numbers(text):\n",
        "    return re.findall(r\"\\d+\\.?\\d*\", text)\n",
        "\n",
        "def factual_difference(text_a, text_b):\n",
        "    nums_a = extract_numbers(text_a)\n",
        "    nums_b = extract_numbers(text_b)\n",
        "\n",
        "    return {\n",
        "        \"numbers_text_a\": nums_a,\n",
        "        \"numbers_text_b\": nums_b,\n",
        "        \"factual_difference\": nums_a != nums_b\n",
        "    }\n"
      ],
      "metadata": {
        "id": "ya8Izybg4GsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7ï¸âƒ£ Contradiction Detection (NLI â€“ Stable Version)\n",
        "Explanation\n",
        "\n",
        "Natural Language Inference classifies the relationship between two texts as entailment, neutral, or contradiction."
      ],
      "metadata": {
        "id": "g-mM6Yd74bLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def contradiction_difference(text_a, text_b):\n",
        "    inputs = tokenizer(\n",
        "        text_a,\n",
        "        text_b,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = nli_model(**inputs).logits\n",
        "\n",
        "    probs = F.softmax(logits, dim=1)[0]\n",
        "    labels = [\"contradiction\", \"neutral\", \"entailment\"]\n",
        "\n",
        "    scores = dict(zip(labels, probs.tolist()))\n",
        "\n",
        "    return {\n",
        "        \"relationship\": max(scores, key=scores.get),\n",
        "        \"confidence\": round(max(scores.values()), 4),\n",
        "        \"contradiction\": scores[\"contradiction\"] > 0.5\n",
        "    }\n"
      ],
      "metadata": {
        "id": "PyXPPuwV4XUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8ï¸âƒ£ Combine All Differences (CORE SYSTEM)\n",
        "Explanation\n",
        "\n",
        "Multiple difference signals are combined to obtain a robust comparison result."
      ],
      "metadata": {
        "id": "cZcB8ZEc4hNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def full_text_difference(text_a, text_b):\n",
        "    return {\n",
        "        \"semantic\": semantic_difference(text_a, text_b),\n",
        "        \"lexical\": lexical_difference(text_a, text_b),\n",
        "        \"factual\": factual_difference(text_a, text_b),\n",
        "        \"contradiction\": contradiction_difference(text_a, text_b)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "7Ytbh5fB4jrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9ï¸âƒ£ Test on Sentences (Baseline Experiment)"
      ],
      "metadata": {
        "id": "jjR7r0Mi4nnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_a = \"The model achieved 92% accuracy and passed all tests.\"\n",
        "text_b = \"The system achieved 90% accuracy and failed several tests.\"\n",
        "\n",
        "full_text_difference(text_a, text_b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSa8HPxb4lB9",
        "outputId": "a974580b-47e1-43dc-fd25-7fb19dd4dbbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'semantic': {'similarity_score': 0.7434, 'semantic_difference': np.True_},\n",
              " 'lexical': {'lexical_similarity': 0.7928, 'lexical_difference': True},\n",
              " 'factual': {'numbers_text_a': ['92'],\n",
              "  'numbers_text_b': ['90'],\n",
              "  'factual_difference': True},\n",
              " 'contradiction': {'relationship': 'contradiction',\n",
              "  'confidence': 0.9992,\n",
              "  'contradiction': True}}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ”Ÿ Threshold Sensitivity Analysis\n",
        "Explanation\n",
        "\n",
        "Threshold analysis studies how similarity decisions change with different thresholds."
      ],
      "metadata": {
        "id": "4OvFXtYm4tP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def threshold_analysis(text_a, text_b, thresholds=[0.6, 0.7, 0.8, 0.9]):\n",
        "    results = {}\n",
        "    for t in thresholds:\n",
        "        results[t] = semantic_difference(text_a, text_b, threshold=t)\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "e297B9LA4pmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold_analysis(text_a, text_b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1SnNqON4vcO",
        "outputId": "7bed9fe0-dbe2-4143-c544-2e9c09657929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.6: {'similarity_score': 0.7434, 'semantic_difference': np.False_},\n",
              " 0.7: {'similarity_score': 0.7434, 'semantic_difference': np.False_},\n",
              " 0.8: {'similarity_score': 0.7434, 'semantic_difference': np.True_},\n",
              " 0.9: {'similarity_score': 0.7434, 'semantic_difference': np.True_}}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def threshold_analysis_full(text_a, text_b, thresholds=[0.6, 0.7, 0.8, 0.9]):\n",
        "    results = {}\n",
        "    for t in thresholds:\n",
        "        results[t] = {\n",
        "            \"semantic\": semantic_difference(text_a, text_b, threshold=t),\n",
        "            \"lexical\": lexical_difference(text_a, text_b),\n",
        "            \"factual\": factual_difference(text_a, text_b),\n",
        "            \"contradiction\": contradiction_difference(text_a, text_b)\n",
        "        }\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "rc2lEKAyBYnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = threshold_analysis_full(text_a, text_b)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y_2iFiBC-z6",
        "outputId": "ebe67511-ca67-4e3d-c5a8-84aa423479dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0.6: {'semantic': {'similarity_score': 0.7434, 'semantic_difference': np.False_}, 'lexical': {'lexical_similarity': 0.7928, 'lexical_difference': True}, 'factual': {'numbers_text_a': ['92'], 'numbers_text_b': ['90'], 'factual_difference': True}, 'contradiction': {'relationship': 'contradiction', 'confidence': 0.9992, 'contradiction': True}}, 0.7: {'semantic': {'similarity_score': 0.7434, 'semantic_difference': np.False_}, 'lexical': {'lexical_similarity': 0.7928, 'lexical_difference': True}, 'factual': {'numbers_text_a': ['92'], 'numbers_text_b': ['90'], 'factual_difference': True}, 'contradiction': {'relationship': 'contradiction', 'confidence': 0.9992, 'contradiction': True}}, 0.8: {'semantic': {'similarity_score': 0.7434, 'semantic_difference': np.True_}, 'lexical': {'lexical_similarity': 0.7928, 'lexical_difference': True}, 'factual': {'numbers_text_a': ['92'], 'numbers_text_b': ['90'], 'factual_difference': True}, 'contradiction': {'relationship': 'contradiction', 'confidence': 0.9992, 'contradiction': True}}, 0.9: {'semantic': {'similarity_score': 0.7434, 'semantic_difference': np.True_}, 'lexical': {'lexical_similarity': 0.7928, 'lexical_difference': True}, 'factual': {'numbers_text_a': ['92'], 'numbers_text_b': ['90'], 'factual_difference': True}, 'contradiction': {'relationship': 'contradiction', 'confidence': 0.9992, 'contradiction': True}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1ï¸âƒ£1ï¸âƒ£ PDF Resume Comparison (Document-Level)\n",
        "Explanation\n",
        "\n",
        "PDF documents are converted to plain text before applying NLP models."
      ],
      "metadata": {
        "id": "yorHvd1A40uz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            if page.extract_text():\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "    return text\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    return \" \".join(text.split())\n"
      ],
      "metadata": {
        "id": "t2YpN9mn4xTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example Usage"
      ],
      "metadata": {
        "id": "JlThgKsE45_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resume_old = clean_text(extract_text_from_pdf(\"VaishnavMankar (1).pdf\"))\n",
        "resume_new = clean_text(extract_text_from_pdf(\"VaishnavMankar (2).pdf\"))\n",
        "\n",
        "full_text_difference(resume_old, resume_new)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dgfnkjkx43cj",
        "outputId": "6cff03fc-95d0-41e4-f2c4-fc4fb97b7e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'semantic': {'similarity_score': 0.995, 'semantic_difference': np.False_},\n",
              " 'lexical': {'lexical_similarity': 0.6533, 'lexical_difference': True},\n",
              " 'factual': {'numbers_text_a': ['919146790431',\n",
              "   '2002',\n",
              "   '2024',\n",
              "   '2026',\n",
              "   '6.55',\n",
              "   '2020',\n",
              "   '2024',\n",
              "   '6.34',\n",
              "   '2025',\n",
              "   '2025',\n",
              "   '2025',\n",
              "   '2025',\n",
              "   '8',\n",
              "   '2024',\n",
              "   '2024'],\n",
              "  'numbers_text_b': ['919146790431',\n",
              "   '2002',\n",
              "   '2024',\n",
              "   '2026',\n",
              "   '6.55',\n",
              "   '2020',\n",
              "   '2024',\n",
              "   '6.34',\n",
              "   '2025',\n",
              "   '2025',\n",
              "   '2025',\n",
              "   '2025',\n",
              "   '2024',\n",
              "   '2024'],\n",
              "  'factual_difference': True},\n",
              " 'contradiction': {'relationship': 'entailment',\n",
              "  'confidence': 0.5525,\n",
              "  'contradiction': False}}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1ï¸âƒ£2ï¸âƒ£ Chunking for Long Documents (Advanced)\n",
        "\n",
        "Explanation\n",
        "\n",
        "Long documents are split into chunks to improve embedding quality."
      ],
      "metadata": {
        "id": "RC-H6Ow850R1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text, chunk_size=300):\n",
        "    words = text.split()\n",
        "    return [\n",
        "        \" \".join(words[i:i + chunk_size])\n",
        "        for i in range(0, len(words), chunk_size)\n",
        "    ]\n"
      ],
      "metadata": {
        "id": "DKVOFWiH48Z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Chunk-wise Semantic Comparison\n",
        "\n",
        "Explanation (for report)\n",
        "\n",
        "Each chunk of document A is compared with all chunks of document B. The maximum similarity score is retained to represent the best semantic match."
      ],
      "metadata": {
        "id": "o3J3-3Oa8hh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chunked_semantic_similarity(text_a, text_b):\n",
        "    chunks_a = chunk_text(text_a)\n",
        "    chunks_b = chunk_text(text_b)\n",
        "\n",
        "    embeddings_a = semantic_model.encode(chunks_a)\n",
        "    embeddings_b = semantic_model.encode(chunks_b)\n",
        "\n",
        "    similarity_matrix = cosine_similarity(embeddings_a, embeddings_b)\n",
        "\n",
        "    # Best match for each chunk in A\n",
        "    max_similarities = similarity_matrix.max(axis=1)\n",
        "\n",
        "    return {\n",
        "        \"avg_similarity\": round(float(np.mean(max_similarities)), 4),\n",
        "        \"min_similarity\": round(float(np.min(max_similarities)), 4),\n",
        "        \"max_similarity\": round(float(np.max(max_similarities)), 4)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "ZRdxyiPn57Bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Chunked Difference Decision"
      ],
      "metadata": {
        "id": "jYd182y_8oTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chunked_semantic_difference(text_a, text_b, threshold=0.8):\n",
        "    stats = chunked_semantic_similarity(text_a, text_b)\n",
        "\n",
        "    return {\n",
        "        **stats,\n",
        "        \"semantic_difference\": stats[\"avg_similarity\"] < threshold\n",
        "    }\n"
      ],
      "metadata": {
        "id": "GWvJVCES8lMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5ï¸âƒ£ Test Chunking on Resumes (THIS IS THE REAL TASK)"
      ],
      "metadata": {
        "id": "5b6iQd4S8uuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunked_semantic_difference(resume_old, resume_new)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qcj5nCtT8p-9",
        "outputId": "5866f324-4576-4809-a5d8-d41921ad795e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'avg_similarity': 0.995,\n",
              " 'min_similarity': 0.995,\n",
              " 'max_similarity': 0.995,\n",
              " 'semantic_difference': False}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6ï¸âƒ£ Why This Output Is Very Valuable for Your Report\n",
        "\n",
        "You can now explain:\n",
        "\n",
        "Average similarity â†’ overall resume similarity\n",
        "\n",
        "Minimum similarity â†’ most changed section\n",
        "\n",
        "Maximum similarity â†’ unchanged section\n",
        "\n",
        "This is much stronger than single-score comparison."
      ],
      "metadata": {
        "id": "oJ3_uR-q81T8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7ï¸âƒ£ Combine Chunking with Other Differences (FINAL SYSTEM)"
      ],
      "metadata": {
        "id": "pkZOjTzn85Dj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def full_document_difference(text_a, text_b):\n",
        "    return {\n",
        "        \"chunked_semantic\": chunked_semantic_difference(text_a, text_b),\n",
        "        \"lexical\": lexical_difference(text_a, text_b),\n",
        "        \"factual\": factual_difference(text_a, text_b),\n",
        "        \"contradiction\": contradiction_difference(text_a, text_b)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "WcvfhoFW8xDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = full_document_difference(text_a, text_b)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UDcI2bX-Xbk",
        "outputId": "86938454-91cf-4d14-a541-8474fdb707f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'chunked_semantic': {'avg_similarity': 0.7434, 'min_similarity': 0.7434, 'max_similarity': 0.7434, 'semantic_difference': True}, 'lexical': {'lexical_similarity': 0.7928, 'lexical_difference': True}, 'factual': {'numbers_text_a': ['92'], 'numbers_text_b': ['90'], 'factual_difference': True}, 'contradiction': {'relationship': 'contradiction', 'confidence': 0.9992, 'contradiction': True}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "{\n",
        "  \n",
        "  'chunked_semantic': {\n",
        "        \n",
        "        'avg_similarity': 0.7434,\n",
        "        'min_similarity': 0.7434,\n",
        "        'max_similarity': 0.7434,\n",
        "        'semantic_difference': True\n",
        "  },\n",
        "   \n",
        "   'lexical': {\n",
        "         \n",
        "         'lexical_similarity': 0.7928,\n",
        "         'lexical_difference': True\n",
        "  },\n",
        "    \n",
        "    'factual': {\n",
        "          'numbers_text_a': ['92'],\n",
        "           'numbers_text_b': ['90'],\n",
        "            'factual_difference': True\n",
        "  },\n",
        "  'contradiction': {\n",
        "           \n",
        "           'relationship': 'contradiction',\n",
        "            'confidence': 0.9992,\n",
        "            'contradiction': True\n",
        "  }\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "id": "ispB494C-l8S"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qA2tkje_-f_s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}